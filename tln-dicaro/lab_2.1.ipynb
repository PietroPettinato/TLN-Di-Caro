{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import numpy as np\n",
    "from nltk import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Esercizio 2.1 - Text summarization estrattivo"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Per questo esercizio è stato scelto come corpus la pagina di Wikipedia sul Natural Language Processing (<https://en.wikipedia.org/wiki/Natural_language_processing>).\n",
    "Il testo è stato recuperato utilizzando _SketchEngine_."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "L'obiettivo è quello di implementare un sistema di __text summarization estrattivo__ che riduca il numero di frasi del documento senza tralasciare informazioni importanti."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Carichiamo il corpus e creiamo un array con le singole frasi."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "data": {
      "text/plain": "array(['Natural language processing',\n       'This article is about natural language processing done by computers.',\n       'For the natural language processing done by the human brain, see Language processing in the brain.',\n       'Natural language processing (NLP) is a subfield of linguistics, computer science, and artificial intelligence concerned with the interactions between computers and human language, in particular how to program computers to process and analyze large amounts of natural language data.',\n       'The goal is a computer capable of \"understanding\" the contents of documents, including the contextual nuances of the language within them.'],\n      dtype='<U423')"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 0\n",
    "all_sentences = np.array([])\n",
    "for line in open('utils/wikipedia_nlp_page.txt', 'r').readlines():\n",
    "    all_sentences = np.append(all_sentences, sent_tokenize(line))\n",
    "all_sentences[:5]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "# creiamo una copia per non modificare le frasi originali in fase di preprocessing (stopwards e punct removal ...)\n",
    "summary = np.copy(all_sentences)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Effettuiamo preprocessing sulle frasi."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "stopwords = []\n",
    "for line in open(\"utils/stop_words_FULL.txt\", 'r').readlines():\n",
    "    stopwords.append(line.rstrip('\\n'))\n",
    "stopwords = np.array(stopwords)\n",
    "\n",
    "# Initializing nltk.PorterStemmer()\n",
    "ps = PorterStemmer()\n",
    "\n",
    "def preprocessing(s):\n",
    "    \"\"\"\n",
    "    Do some preprocessing operations on the string.\n",
    "\n",
    "    :param s: the string\n",
    "\n",
    "    :return: the preprocessed string\n",
    "    \"\"\"\n",
    "    # Lowercasing\n",
    "    s = s.lower()\n",
    "    # Punct removal\n",
    "    s = s.translate(str.maketrans('', '', string.punctuation))\n",
    "    # Stopword removal\n",
    "    s = ' '.join([word for word in s.split() if word not in stopwords])\n",
    "    # Stemming\n",
    "    # s = ' '.join([ps.stem(word) for word in s.split()])\n",
    "    return s"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "data": {
      "text/plain": "array(['natural language processing',\n       'article natural language processing computers',\n       'natural language processing human brain language processing brain',\n       'natural language processing nlp subfield linguistics computer science artificial intelligence concerned interactions computers human language program computers process analyze large amounts natural language data',\n       'goal computer capable understanding contents documents including contextual nuances language'],\n      dtype='<U299')"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect_preprocessing = np.vectorize(preprocessing) # vettorizziamo la funzione in modo da applicarla a tutto l'array di frasi\n",
    "summary = vect_preprocessing(summary)\n",
    "summary[:5]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Contiamo le frequenze delle parole per usarle come pesi la valutazione dell'importanza delle frasi."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "def get_frequencies(sents):\n",
    "    \"\"\"\n",
    "    Function to get first 4 frequent words.\n",
    "\n",
    "    :param sents: a list of sentences\n",
    "\n",
    "    :return: a dictionary of words with their frequency in the given sentences\n",
    "    \"\"\"\n",
    "    words = []\n",
    "    for s in sents:\n",
    "        words += word_tokenize(s)\n",
    "    # contiamo le parole in un dizionario\n",
    "    counts = dict.fromkeys(words, 0) # inizializziamo i conteggi di tutte le parole a 0\n",
    "    for w in words:\n",
    "        counts[w] += 1\n",
    "    return counts"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "frequencies = get_frequencies(summary)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "data": {
      "text/plain": "'\\nvedere questa guida -->  https://medium.com/analytics-vidhya/simple-text-summarization-using-nltk-eedc36ebaaf8\\n\\n1) caricare il testo\\n2) dividere il testo in frasi (nltk.sent_tokenizer())\\n3) preprocessing sulle frasi\\n\\n// come valutare quali frasi sono importanti??\\n4) trovare le n parole più frequenti nel testo\\n5) scegliere solo le frasi contenenti x parole frequenti\\n6) stampare il riassunto mostrando la riduzione in termini di frasi tolte\\n'"
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "vedere questa guida -->  https://medium.com/analytics-vidhya/simple-text-summarization-using-nltk-eedc36ebaaf8\n",
    "\n",
    "1) caricare il testo\n",
    "2) dividere il testo in frasi (nltk.sent_tokenizer())\n",
    "3) preprocessing sulle frasi\n",
    "\n",
    "// come valutare quali frasi sono importanti??\n",
    "4) trovare le n parole più frequenti nel testo\n",
    "5) scegliere solo le frasi contenenti x parole frequenti\n",
    "6) stampare il riassunto mostrando la riduzione in termini di frasi tolte\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}