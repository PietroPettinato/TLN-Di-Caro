{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from nltk.corpus import movie_reviews as mr\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Esercizio 1.4 - Teoria di Hanks"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Per questo esercizio viene utilizzato il corpus _movie reviews_ di NLTK, contenente recensioni di film."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "# nltk.download(\"movie_reviews\")\n",
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Dal corpus recuperriamo 1000 frasi contenenti il verbo _get_."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "array(['they get into an accident .',\n       \"now i personally don't mind trying to unravel a film every now and then , but when all it does is give me the same clue over and over again , i get kind of fed up after a while , which is this film's biggest problem .\",\n       'okay , we get it .',\n       \"you're more likely to get a kick out of her work in halloween h20 .\",\n       'all this to get to the familiar yet offensive \" revelation \" that sexual deviants are not , indeed , monsters but everyday people like you and me .'],\n      dtype='<U887')"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_sentences(verb, corpus, num):\n",
    "    \"\"\"\n",
    "    Given a corpus and a verb return the number of senteneces specified in the limit.\n",
    "\n",
    "    :param verb: the verb as a string\n",
    "    :param corpus: the corpus in which the search must be done\n",
    "    :param num: the number of sentences to retrieve\n",
    "\n",
    "    :return: the list of sentences containing the verb\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    sentences = np.array([])\n",
    "    while len(sentences) < num:\n",
    "        review = corpus.raw(corpus.fileids()[i])\n",
    "        if verb in review.split():\n",
    "            for s in sent_tokenize(review): # le recensioni contengono piÃ¹ frasi, le dividiamo considerandole singolarmente\n",
    "                if verb in s.split():\n",
    "                    sentences = np.append(sentences, s)\n",
    "        i += 1\n",
    "    return sentences\n",
    "\n",
    "\n",
    "sentences = get_sentences('get', mr, 1000)\n",
    "sentences[:5]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Effettuiamo parsing e disambiguazione"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'parser_dirname'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_2851/2727767299.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     14\u001B[0m \"\"\")\n\u001B[1;32m     15\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 16\u001B[0;31m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mMaltParser\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mraw_parse\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msentences\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m: __init__() missing 1 required positional argument: 'parser_dirname'"
     ]
    }
   ],
   "source": [
    "from nltk.parse.stanford import StanfordParser, GenericStanfordParser\n",
    "from nltk.parse.malt import MaltParser\n",
    "from nltk import CFG\n",
    "\n",
    "grammar = CFG.fromstring(\"\"\"\n",
    "    S -> NP VP\n",
    "    PP -> P NP\n",
    "    NP -> Det N | NP PP\n",
    "    VP -> V NP | VP PP\n",
    "    Det -> 'a' | 'the'\n",
    "    N -> 'dog' | 'cat'\n",
    "    V -> 'chased' | 'sat'\n",
    "    P -> 'on' | 'in'\n",
    "\"\"\")\n",
    "\n",
    "print(MaltParser().raw_parse(sentences[0]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'parser_dirname'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_2851/3396961031.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;31m# With MALT_PARSER and MALT_MODEL environment set.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 4\u001B[0;31m \u001B[0mmp\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmalt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mMaltParser\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel_filename\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'engmalt.linear-1.7.mco'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      5\u001B[0m \u001B[0mmp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mparse_one\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'I shot an elephant in my pajamas .'\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msplit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtree\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[0;31m# (shot I (elephant an) (in (pajamas my)) .)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mTypeError\u001B[0m: __init__() missing 1 required positional argument: 'parser_dirname'"
     ]
    }
   ],
   "source": [
    "from nltk.parse import malt\n",
    "\n",
    "# With MALT_PARSER and MALT_MODEL environment set.\n",
    "mp = malt.MaltParser(model_filename='engmalt.linear-1.7.mco')\n",
    "mp.parse_one('I shot an elephant in my pajamas .'.split()).tree()\n",
    "# (shot I (elephant an) (in (pajamas my)) .)\n",
    "# Without MALT_PARSER and MALT_MODEL environment.\n",
    "mp = malt.MaltParser('/home/user/maltparser-1.9.2/', '/home/user/engmalt.linear-1.7.mco')\n",
    "mp.parse_one('I shot an elephant in my pajamas .'.split()).tree()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}